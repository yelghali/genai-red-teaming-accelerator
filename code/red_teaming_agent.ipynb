{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e16da97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from openai import AzureOpenAI\n",
    "# Define the path to the .env file\n",
    "env_path = Path('/workspaces/genai-red-teaming-accelerator/code/.env')\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "dotenv.load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "\n",
    "#set env var\n",
    "os.environ['OPENAI_CHAT_ENDPOINT'] = \"https://yayagot4o.openai.azure.com/openai/deployments/gpt-4o/chat/completions\"\n",
    "os.environ['OPENAI_CHAT_API_KEY'] = \"\"\n",
    "os.environ['OPENAI_CHAT_MODEL'] = \"gpt-4o\"\n",
    "\n",
    "print(os.getenv('OPENAI_CHAT_ENDPOINT'))  \n",
    "print(os.getenv('OPENAI_CHAT_API_KEY')) \n",
    "print(os.getenv('OPENAI_CHAT_MODEL'))\n",
    "print(os.getenv('PLATFORM_OPENAI_CHAT_ENDPOINT'))\n",
    "\n",
    "azure_openai_client = client = AzureOpenAI(\n",
    "    azure_endpoint=\"https://yayagot4o.openai.azure.com/\",\n",
    "    api_key=os.getenv('OPENAI_CHAT_API_KEY'),\n",
    "    api_version=\"2025-01-01-preview\",\n",
    ")\n",
    "\n",
    "\n",
    "# Azure OpenAI\n",
    "AZURE_OPENAI_API_KEY=\"\"\n",
    "AZURE_OPENAI_ENDPOINT=\"https://yayagot4o.openai.azure.com/openai/deployments/gpt-4o/chat/completions\"\n",
    "AZURE_OPENAI_DEPLOYMENT_NAME=\"gpt-4o\"\n",
    "AZURE_OPENAI_API_VERSION=\"2025-01-01-preview\"\n",
    "\n",
    "# Azure AI Project\n",
    "AZURE_SUBSCRIPTION_ID=\"\"\n",
    "AZURE_RESOURCE_GROUP_NAME=\"rg-yaelghalai\"\n",
    "AZURE_PROJECT_NAME=\"yaelghal-7706\"\n",
    "\n",
    "os.environ['AZURE_OPENAI_API_KEY'] = AZURE_OPENAI_API_KEY\n",
    "os.environ['AZURE_OPENAI_ENDPOINT'] = AZURE_OPENAI_ENDPOINT\n",
    "os.environ['AZURE_OPENAI_DEPLOYMENT_NAME'] = AZURE_OPENAI_DEPLOYMENT_NAME\n",
    "os.environ['AZURE_OPENAI_API_VERSION'] = AZURE_OPENAI_API_VERSION\n",
    "os.environ['AZURE_SUBSCRIPTION_ID'] = AZURE_SUBSCRIPTION_ID\n",
    "os.environ['AZURE_RESOURCE_GROUP_NAME'] = AZURE_RESOURCE_GROUP_NAME\n",
    "os.environ['AZURE_PROJECT_NAME'] = AZURE_PROJECT_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from fastapi import FastAPI, Request, HTTPException\n",
    "from pydantic import BaseModel\n",
    "import httpx\n",
    "from typing import List\n",
    "from threading import Thread\n",
    "import uvicorn\n",
    "import tempfile\n",
    "import shutil\n",
    "\n",
    "\n",
    "\n",
    "app = FastAPI()\n",
    "CONV_FILE = \"conversations.json\"\n",
    "AZURE_OPENAI_URL = os.environ.get(\"OPENAI_CHAT_ENDPOINT\") + \"?api-version=2024-02-15-preview\"\n",
    "AZURE_OPENAI_KEY = os.environ.get(\"OPENAI_CHAT_API_KEY\")\n",
    "\n",
    "class MyPromptRequest(BaseModel):\n",
    "    user_prompt: str\n",
    "    conversation_id: str\n",
    "\n",
    "def load_conversations():\n",
    "    if not os.path.exists(CONV_FILE):\n",
    "        return {}\n",
    "    try:\n",
    "        with open(CONV_FILE, \"r\") as f:\n",
    "            content = f.read().strip()\n",
    "            if not content:\n",
    "                return {}\n",
    "            return json.loads(content)\n",
    "    except (json.JSONDecodeError, IOError) as e:\n",
    "        print(f\"Warning: Could not load conversations ({e}), starting fresh.\")\n",
    "        return {}\n",
    "\n",
    "def save_conversations(conversations):\n",
    "    # Write to a temp file first, then move to avoid corruption\n",
    "    temp_fd, temp_path = tempfile.mkstemp()\n",
    "    try:\n",
    "        with os.fdopen(temp_fd, \"w\") as tmpf:\n",
    "            json.dump(conversations, tmpf)\n",
    "        shutil.move(temp_path, CONV_FILE)\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving conversations: {e}\")\n",
    "        if os.path.exists(temp_path):\n",
    "            os.remove(temp_path)\n",
    "\n",
    "@app.post(\"/chat\")\n",
    "async def chat(req: MyPromptRequest):\n",
    "    print(f\"Received request: user_prompt={repr(req.user_prompt)} conversation_id={repr(req.conversation_id)}\")\n",
    "    if not req.user_prompt or not req.conversation_id:\n",
    "        raise HTTPException(status_code=400, detail=\"user_prompt and conversation_id are required\")\n",
    "    conversations = load_conversations()\n",
    "    conv = conversations.get(req.conversation_id, [])\n",
    "    conv.append({\"role\": \"user\", \"content\": req.user_prompt})\n",
    "    try:\n",
    "        response = azure_openai_client.chat.completions.create(\n",
    "            model=os.getenv('OPENAI_CHAT_MODEL'),\n",
    "            messages=conv,\n",
    "            max_tokens=1000,\n",
    "            temperature=0.7,\n",
    "            stream=False\n",
    "        )\n",
    "        data = response.choices[0].message\n",
    "        conv.append({\"role\": \"assistant\", \"content\": data.content})\n",
    "        conversations[req.conversation_id] = conv\n",
    "        save_conversations(conversations)\n",
    "        print(\"returning response:\", json.loads(response.to_json()))\n",
    "        return json.loads(response.to_json())\n",
    "    except Exception as e:\n",
    "        print(f\"Error during OpenAI API call: {e}\")\n",
    "        raise HTTPException(status_code=500, detail=\"Error processing request\")\n",
    "\n",
    "def run_api():\n",
    "    uvicorn.run(app, host=\"127.0.0.1\", port=8000, log_level=\"info\")\n",
    "\n",
    "# Start FastAPI in a background thread\n",
    "api_thread = Thread(target=run_api, daemon=True)\n",
    "api_thread.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "\n",
    "\n",
    "### AOAI example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51eb3a6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Azure imports\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.evaluation.red_team import RedTeam, RiskCategory\n",
    "\n",
    "# Azure AI Project Information\n",
    "azure_ai_project = {\n",
    "    \"subscription_id\": os.environ.get(\"AZURE_SUBSCRIPTION_ID\"),\n",
    "    \"resource_group_name\": os.environ.get(\"AZURE_RESOURCE_GROUP_NAME\"),\n",
    "    \"project_name\": os.environ.get(\"AZURE_PROJECT_NAME\"),\n",
    "}\n",
    "\n",
    "# Instantiate your AI Red Teaming Agent\n",
    "red_team_agent = RedTeam(\n",
    "    azure_ai_project=azure_ai_project, # required\n",
    "    credential=DefaultAzureCredential(), # required\n",
    "    risk_categories=[ # optional, defaults to all four risk categories\n",
    "        RiskCategory.Violence,\n",
    "        RiskCategory.HateUnfairness,\n",
    "        RiskCategory.Sexual,\n",
    "        RiskCategory.SelfHarm\n",
    "    ], \n",
    "    num_objectives=5, # optional, defaults to 10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9664b497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for Azure OpenAI model\n",
    "azure_openai_config = {\n",
    "    \"azure_endpoint\": os.environ.get(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    \"api_key\": os.environ.get(\"AZURE_OPENAI_KEY\"), #  not needed for entra ID based auth, use az login before running,\n",
    "    \"azure_deployment\": os.environ.get(\"AZURE_OPENAI_DEPLOYMENT\"),\n",
    "}\n",
    "\n",
    "red_team_result = await red_team_agent.scan(target=azure_openai_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f843731f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple callback function that simulates a chatbot\n",
    "def simple_callback(query: str) -> str:\n",
    "    # Your implementation to call your application (e.g., RAG system, chatbot)\n",
    "    return \"I'm an AI assistant that follows ethical guidelines. I cannot provide harmful content.\"\n",
    "\n",
    "red_team_result = await red_team_agent.scan(target=simple_callback)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af920ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "from azure.ai.evaluation.red_team import AttackStrategy\n",
    "\n",
    "\n",
    "# async def myapi_callback(query: str) -> str:\n",
    "#     payload = {\n",
    "#         \"user_prompt\": query,\n",
    "#         \"conversation_id\": \"PromptSendingOrchestrator\"\n",
    "#     }\n",
    "#     async with httpx.AsyncClient() as client:\n",
    "#         response =  await client.post(\n",
    "#             \"http://127.0.0.1:8000/chat\",\n",
    "#             json=payload,\n",
    "#             headers={\"Content-Type\": \"application/json\"}\n",
    "#         )\n",
    "#         #response.raise_for_status()\n",
    "#         print(\"COUCOUCOUCOUCOUICOUCOU\")\n",
    "#         print(response.json()[\"choices\"][0][\"message\"][\"content\"])\n",
    "#         return response.json()[\"choices\"][0][\"message\"][\"content\"] or \"error\"\n",
    "\n",
    "# #test the callback function\n",
    "# response = await myapi_callback(\"What is the capital of France?\")\n",
    "# print(response)  # Should print the response from your FastAPI application\n",
    "\n",
    "\n",
    "def myapi_callback(query: str) -> str:\n",
    "    payload = {\n",
    "        \"user_prompt\": query,\n",
    "        \"conversation_id\": \"PromptSendingOrchestrator\"\n",
    "    }\n",
    "    with httpx.Client() as client:\n",
    "        response = client.post(\n",
    "            \"http://127.0.0.1:8000/chat\",\n",
    "            json=payload,\n",
    "            headers={\"Content-Type\": \"application/json\"}\n",
    "        )\n",
    "        # response.raise_for_status()\n",
    "        print(\"COUCOUCOUCOUCOUICOUCOU\")\n",
    "        print(\"Red teaming agent question:\" + query)\n",
    "        print(\"target response: \"+ response.json()[\"choices\"][0][\"message\"][\"content\"])\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"] or \"error\"\n",
    "\n",
    "red_team_result = await red_team_agent.scan(target=myapi_callback, attack_strategies=[ # optional\n",
    "        AttackStrategy.EASY, \n",
    "        AttackStrategy.MODERATE,  \n",
    "        AttackStrategy.DIFFICULT,\n",
    "    ],)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edb6ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyrit.prompt_target import OpenAIChatTarget, PromptChatTarget\n",
    "\n",
    "# Create a PyRIT PromptChatTarget for an Azure OpenAI model\n",
    "# This could be any class that inherits from PromptChatTarget\n",
    "chat_target = OpenAIChatTarget(\n",
    "    model_name=os.environ.get(\"AZURE_OPENAI_DEPLOYMENT\"),\n",
    "    endpoint=os.environ.get(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.environ.get(\"AZURE_OPENAI_KEY\")\n",
    ") \n",
    "\n",
    "red_team_result = await red_team_agent.scan(target=chat_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21653237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from azure.ai.evaluation.red_team import AttackStrategy\n",
    "\n",
    "# # Run the red team scan with multiple attack strategies\n",
    "# red_team_agent_result = await red_team_agent.scan(\n",
    "#     target=http_prompt_target, # required\n",
    "#     scan_name=\"Scan with many strategies\", # optional, names your scan in Azure AI Foundry\n",
    "#     attack_strategies=[ # optional\n",
    "#         AttackStrategy.EASY, \n",
    "#         AttackStrategy.MODERATE,  \n",
    "#         AttackStrategy.DIFFICULT,\n",
    "#     ],\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
